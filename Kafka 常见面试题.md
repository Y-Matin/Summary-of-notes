### Kafka 面试题

#### 如何防止消息丢失

#### 


#### 如何避免kafka消息重复消费
 - 造成原因
   - 应用程序异常关闭，导致offset为提交
     - 默认情况下，消息消费完成以后，会自动提交Offset这样一个值，避免重复消费。
     - Kafka自动提交的逻辑里面，有一个默认5秒的一个间隔，也就是说在5秒之后的下一次向Broker去获取消息的时候来实现Offset的一个提交。所以在Consumer的消费过程中，应用程序强制被kill掉或者宕机的时候，可能会导致Offset没有提交，从而会产生重复消费的问题。
 - 解决方法
   - 提高消费端处理性能
   - 生成md5 用来判断是否消费过
   - 业务满足幂等的方式


#### 如何增加吞吐量

####  分区的目的
分区对于 Kafka 集群的好处是：实现负载均衡。分区对于消费者来说，可以提高并发度，提高效率。

####  Kafka 是如何做到消息的有序性？
- kafka 中的每个 partition 中的消息在写入时都是有序的，而且单独一个 partition只能由一个消费者去消费，可以在里面保证消息的顺序性。
- 但是分区之间的消息是不保证有序的。 

#### Kafka 的高可靠性是怎么实现的？ 数据不丢失
- ack的三种机制：request.required.acks 有三个值 0 1 -1(all)
  - ack为0： 表示生产者不会等待服务器的确认
  - ack为1： 默认模式，表示生产者会在消息发送后，等待leader的确认，但不会等待flower 的确认
  - ack为-1：这是最可靠模式。在这种模式下，生产者会在消息发送后等待所有副本的确认，只有所有副本都写入消息成功后，生产者才会收到确认。保证了消息的可靠性，但性能较低
  - 


#### kafka消费者端的rebalance什么时候回被触发
- 同一个 consumer 消费者组 group.id 中，新增了消费者进来，会执行 Rebalance 操作
- 消费者离开当期所属的 consumer group组。比如宕机
- 分区数量发生变化时(即 topic 的分区数量发生变化时)
- 消费者主动取消订阅
- 
#### 谈一谈 Kafka 的再均衡
第一步：所有成员都向coordinator发送请求，请求入组。一旦所有成员都发送了请求，coordinator会从中选择一个consumer担任leader的角色，并把组成员信息以及订阅信息发给leader。

第二步：leader开始分配消费方案，指明具体哪个consumer负责消费哪些topic的哪些partition。一旦完成分配，leader会将这个方案发给coordinator。coordinator接收到分配方案之后会把方案发给各个consumer，这样组内的所有成员就都知道自己应该消费哪些分区了。

所以对于Rebalance来说，Coordinator起着至关重要的作用


#### Kafka 的每个分区只能被一个消费者线程，如何做到多个线程同时消费一个分区？
需要借助Spark streaming 


#### Kafka 消费者是否可以消费指定分区消息？
Kafa consumer消费消息时，向broker发出fetch请求去消费特定分区的消息，consumer指定消息在日志中的偏移量（offset），就可以消费从这个位置开始的消息，customer拥有了offset的控制权，可以向后回滚去重新消费之前的消息，这是很有意义的


#### 谈谈 Kafka 分区分配策略


####  Kafka 是如何实现高吞吐率的？
Kafka是分布式消息系统，需要处理海量的消息，Kafka的设计是把所有的消息都写入速度低容量大的硬盘，以此来换取更强的存储能力，但实际上，使用硬盘并没有带来过多的性能损失。 kafka主要使用了以下几个方式实现了超高的吞吐率：

    顺序读写；
    零拷贝
    文件分段
    批量发送
    数据压缩。

#### 如何为Kafka集群选择合适的Topics/Partitions数量


#### Kafka 缺点？

#### Kafka 分区数可以增加或减少吗？为什么？

我们可以使用 bin/kafka-topics.sh命令对 Kafka 增加 Kafka 的分区数据，但是 Kafka 不支持减少分区数。

Kafka 分区数据不支持减少是由很多原因的，比如减少的分区其数据放到哪里去？是删除，还是保留？删除的话，那么这些没消费的消息不就丢了。如果保留这些消息如何放到其他分区里面？追加到其他分区后面的话那么就破坏了 Kafka 单个分区的有序性。如果要保证删除分区数据插入到其他分区保证有序性，那么实现起来逻辑就会非常复杂。
